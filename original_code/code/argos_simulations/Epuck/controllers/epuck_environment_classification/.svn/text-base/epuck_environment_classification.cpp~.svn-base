/* Include the controller definition */
#include "epuck_environment_classification.h"
/* Function definitions for XML parsing */
#include <argos3/core/utility/configuration/argos_configuration.h>
/* 2D vector definition */
#include <argos3/core/utility/math/vector2.h>

/* Definition of the range and bearing actuator */
#include <argos3/plugins/robots/e-puck/control_interface/ci_epuck_range_and_bearing_actuator.h>
/* Definition of the range and bearing sensor */
#include <argos3/plugins/robots/e-puck/control_interface/ci_epuck_range_and_bearing_sensor.h>

/* Definition of the range and bearing sensor */
#include <argos3/plugins/robots/generic/control_interface/ci_range_and_bearing_sensor.h>
#include <argos3/plugins/robots/generic/control_interface/ci_range_and_bearing_actuator.h>

#include <argos3/plugins/robots/e-puck/simulator/epuck_entity.h>
#include <argos3/core/simulator/simulator.h>

#include <stdio.h>
#include <stdlib.h>
#include <ctime>
#include <vector>   
#include <string>   
#include <iostream>
#include <fstream> 

#define ALPHA_CHANNEL		 0
#define COLOR_STRENGHT           255
#define MAX_LISTENING_TIME       40
#define N_COL			 3

/****************************************/
/****************************************/

EPuck_Environment_Classification::EPuck_Environment_Classification() :
   m_pcWheels (NULL), 
   m_fWheelVelocity (10.0f),
   m_pcRABA (NULL),
   m_pcRABS (NULL),
   m_cAlpha (10.0f),
   m_fDelta(0.5f),
   m_pcProximity(NULL),
   bigRange (0.0f,30000.0f),
   zeroOne (0.0f, 1.0f),
   m_cGoStraightAngleRange(-ToRadians(m_cAlpha),
                            ToRadians(m_cAlpha)) {}

EPuck_Environment_Classification::CollectedData::CollectedData() :
   count (1),
   lastCell (0) {}

EPuck_Environment_Classification::Opinion::Opinion() :
   countedCellOfActualOpinion (0)  {}


EPuck_Environment_Classification::Movement::Movement() :
   walkTime (3),
   actualDirection (0){}

/****************************************/
/****************************************/



/************************************************* INIT ********************************************************/
/***************************************************************************************************************/
void EPuck_Environment_Classification::SimulationState::Init(TConfigurationNode& t_node) {

   try{
	      /* Getting sigma, G value and the decision rule to follow */
	      GetNodeAttribute(t_node, "g", g);
	      GetNodeAttribute(t_node, "sigma", sigma);
	      GetNodeAttribute(t_node, "decision_rule", decision_rule);
        }
   catch(CARGoSException& ex) {
      THROW_ARGOSEXCEPTION_NESTED("Error initializing controller state parameters.", ex);
   }
}
 
void EPuck_Environment_Classification::Init(TConfigurationNode& t_node) {
   
   /* Initialize the actuators (and sensors) and the initial velocity as straight walking*/
   m_pcWheels    = GetActuator<CCI_DifferentialSteeringActuator>("differential_steering");
   m_pcProximity = GetSensor <CCI_EPuckProximitySensor >("epuck_proximity");
   m_pcLEDs      = GetActuator<CCI_LEDsActuator                  >("leds");
   m_pcRABA      = GetActuator<CCI_EPuckRangeAndBearingActuator     >("epuck_range_and_bearing"    );
   m_pcRABS      = GetSensor  <CCI_EPuckRangeAndBearingSensor       >("epuck_range_and_bearing"    );
   m_pcRNG = CRandom::CreateRNG("argos");
   m_cGoStraightAngleRange.Set(-ToRadians(m_cAlpha), ToRadians(m_cAlpha));
   GetNodeAttributeOrDefault(t_node, "velocity", m_fWheelVelocity, m_fWheelVelocity);
   simulationParams.Init(GetNode(t_node, "simulation_parameters"));

   /* G and SIGMA have to been inserted in seconds in the configuration file. For this reason here are multiplied*10 (secods*10 = ticks) */
   simulationParams.sigma = simulationParams.sigma*10;
   simulationParams.g = simulationParams.g*10;
  
   /* Colours read from robots could be changed and added here! AGGIUNGERECOLORI */ 
   red.Set(COLOR_STRENGHT,0,0,ALPHA_CHANNEL);      // Change alphachannel has not effect visively, but changing COLOR_STRENGHT could make 
   green.Set(0,COLOR_STRENGHT,0,ALPHA_CHANNEL);    // cells more or less bright
   blue.Set(0,0,COLOR_STRENGHT,ALPHA_CHANNEL);

   /* Assign a random time for the exploration and diffusing states. "RemainingTime" are the ones decremented and checked to see if
    * the state is finished. "DurationTime" are the ones used for catching statistics and save the times */
   m_sStateData.remainingExplorationTime = (m_pcRNG->Exponential(simulationParams.sigma));
   m_sStateData.explorDurationTime = m_sStateData.remainingExplorationTime;

   /* Statistic variables (not anymore used here but could be helpfull sometimes to catch statistics) */
   for(int c = 0; c<N_COL; c++)
   {
	m_sStateData.numberOfExplorations[c] = 1;
        m_sStateData.numberOfDiffusions[c] = 1;
        m_sStateData.exportTime[c] = 0;
        countedOfThisOpinion[c] = 0;
        totalCounted = 0;
   	opinion.exportQuality[c] = 0;
   }


   /* IC it's an helping variable to read others opinion */
   IC.receivedOpinion = 0;
   IC.receivedQuality = 0;
   IC.senderID = 0;
  
   /* Assign the initial state of the robots: all in exploration state*/
   m_sStateData.State = SStateData::STATE_EXPLORING;

   /* INITIAL QUALITY: has to be estimated in the first exploration state */
   opinion.quality = 0;    
}

/************************************************* CONTROL STEP ************************************************/
/***************************************************************************************************************/
void EPuck_Environment_Classification::ControlStep() {

  /* Turn leds according with actualOpinion */
  TurnLeds();
 
  /* Move robots following randomWalk */
  Move();

  /* Two different behaviours, depending on if they are diffusing or exploring */
  switch(m_sStateData.State) {
      
      case SStateData::STATE_EXPLORING: {
	 Explore();
         break;
      }

      case SStateData::STATE_DIFFUSING: {
         Diffusing();
         break;
      }
   } 


/**** OBSTACLE AVOIDANCE (just leave it like it is) ****/

/* Get readings from proximity sensor and sum them together */
const CCI_EPuckProximitySensor::TReadings& tProxReads = m_pcProximity->GetReadings();
CVector2 cAccumulator;
for(size_t i = 0; i < tProxReads.size(); ++i) {
    cAccumulator += CVector2(tProxReads[i].Value, tProxReads[i].Angle);
}
if(tProxReads.size()>0)
cAccumulator /= tProxReads.size();

/* If the angle of the vector is not small enough or the closest obstacle is not far enough curve a little */
CRadians cAngle = cAccumulator.Angle();
  if(!(m_cGoStraightAngleRange.WithinMinBoundIncludedMaxBoundIncluded(cAngle) && cAccumulator.Length() < m_fDelta )) {
     /* Turn, depending on the sign of the angle */
     if(cAngle.GetValue() > 0.0f) {
        m_pcWheels->SetLinearVelocity(m_fWheelVelocity, 0.0f);
     }
     else {
        m_pcWheels->SetLinearVelocity(0.0f, m_fWheelVelocity);
     }
  }
}


/************************************************* EXPLORING STATE *********************************************/
/***************************************************************************************************************/
void EPuck_Environment_Classification::Explore() {
  
	/* remainingExplorationTime it's the variable decremented each control step. 
	 * This variable represents the time that a robot must still spend in exploration state.
	 * If this variable it's greater than zero, then it must be decremented and the robot should 
	 * do exploration's stuffs (Update counters figuring out in which cell he is. It's done in loop function */
	if(m_sStateData.remainingExplorationTime > 0){		
  	     m_sStateData.remainingExplorationTime--;
         }

	/* If its time to change state, then the robot has to reset his own variables:
	 * - Assign a new random exponential time: remainingExplorationTime and explorDurationTime (used to
	 *   keep trace of the exploration times, just for statistic aims);
	 * - Calculate the quality of the opinion, basing on the sensed datas (Number of counted cells of actual
	 *   opinion / Number of total counted cells);
	 * - Reset counting variables (countedCellOfActualOpinion and count [total number of cells counted]);
	 * - Change state: Exploration->Diffusing;
	 * - Generate a new Diffusing time (same as exploring, but used for Diffusing state and calculated with
	 *   different params for the random variable;
	 */
	else{ 
    	   m_sStateData.remainingExplorationTime = (m_pcRNG->Exponential(simulationParams.sigma)); 
	   m_sStateData.explorDurationTime = m_sStateData.remainingExplorationTime;                

	   opinion.quality = (Real)((Real)(opinion.countedCellOfActualOpinion)/(Real)(collectedData.count));      
	   opinion.countedCellOfActualOpinion = 0; 

	   collectedData.count = 1;                  

           m_sStateData.State = SStateData::STATE_DIFFUSING; 	
	   m_sStateData.remainingDiffusingTime = (m_pcRNG->Exponential((simulationParams.g)*(opinion.quality)))+30;
           m_sStateData.diffusingDurationTime = m_sStateData.remainingDiffusingTime;

	 }
}

/************************************************* DIFFUSING STATE *********************************************/
/***************************************************************************************************************/
void EPuck_Environment_Classification::Diffusing() {
  
  /* remainingDiffusingTime>0 means that is still time to perform diffusing state */
  if (m_sStateData.remainingDiffusingTime > 0) 
  {	
    /* In the 3 lasts seconds (30 ticks) the robot starts listening other opinions 
     * and diffusing his own opinion, quality and ID */ 
    if(  m_sStateData.remainingDiffusingTime < 30 ) 
       {
	 /* Every received data is stored in IC variable (helping var). Each IC variable will be 
	  * inserted in receivedOpinions array if has not been sensed yet and it's not a 0,0,0 one. 
	  * It will be used to choose the next opinion, basing on decision rules. After a decision 
	  * has been taken this array will be emptied for the next diffusing state. */
         const CCI_EPuckRangeAndBearingSensor::TPackets& tPackets = m_pcRABS->GetPackets();

	 for(size_t i = 0; i < tPackets.size() ; ++i) {

	       bool saved = false;   // saved = variable to not save opinions twice: if saved == true -> don't save the datas

	       /* IC = Helping variable for sensed opinions */
               IC.receivedOpinion = tPackets[i]->Data[0]; /* Store received opinion */
	       IC.senderID = tPackets[i]->Data[3];        /* Store id of the sender. The id has been sent using a number, that is the 
					                   * conversion of the string id

	       /* Loop for sense quality value: quality has been sent using 3 cells of RAB datas, 
		* so here it will converted in a Real number */
 	       IC.receivedQuality=0;
               for ( int j = 1; j<3 ; ++j)
                     IC.receivedQuality = IC.receivedQuality*100 + tPackets[i]->Data[j];
	       IC.receivedQuality = (Real) IC.receivedQuality / 10000;

	       /* Don't want to save already listened values */
               for(int j = 0; j < receivedOpinions.size(); ++j)
                   if(receivedOpinions[j].senderID == IC.senderID) 
                      saved = true;
	       
	       /* Don't want to save 0,0,0 values */
	       if(IC.senderID == 0)
		  saved = true;

	       /* Save value if it has not been already saved and it's not 0,0,0 value  */
              if(!saved) 
                  receivedOpinions.push_back(IC);
	 }
       }

      /* LEDS must be lighted with intermittence in diffusing state */
      if(m_sStateData.remainingDiffusingTime%3)
	 m_pcLEDs->SetAllColors(CColor::BLACK); 

      /* Following things will have always to be done if in diffusing state. Here robot sends its opinion,
       * quality and ID */
      CCI_EPuckRangeAndBearingActuator::TData toSend;

      /* Send opinion */
      toSend[0] = opinion.actualOpinion;  

      /* Send quality */
      Real p = opinion.quality;   // helping variables
      UInt8 t;			  // helping variables
      for (int i = 0; i < 2; ++i)
	{
	   p = p*100;
	   t = (int)p;
           p = p - t;
	   toSend[i+1] = t;
        }
      
      /* Send ID: an univoque transformation of the string id is calculated	
       * by using the ASCII charachter of the string, and then it will be 
       * sent to the other robots */
      std::string id = GetId();
      int idConversion = 0;
      for ( int i = 2; id[i] != '\0'; ++i )
      {
         idConversion += int(id[i]);
         idConversion = idConversion*10;
      }  
    // m_pcRABA->SetData(idConversion);
      toSend[3] = idConversion;
      
      m_pcRABA->SetData(toSend);
      m_sStateData.remainingDiffusingTime--;	
  }
  else // Time to change to exploration state
    {
      /* Reset exponential random diffusing time */
      m_sStateData.remainingDiffusingTime = m_pcRNG->Exponential((simulationParams.g)*(opinion.quality))+30;    
      m_sStateData.diffusingDurationTime = m_sStateData.remainingDiffusingTime;

      /* Change to EXPLORING state and choose another opinion with decision rules */
      m_sStateData.State = SStateData::STATE_EXPLORING;
      DecisionRule(simulationParams.decision_rule);

      /* After decision has been taken, sensed values are deleted */
      receivedOpinions.clear();   
  }
}

/* DECISION RULE */
void EPuck_Environment_Classification::DecisionRule(int decision_rule)
{

     switch(decision_rule) {
      
      case 1: {
         VoterModel();
         break;
      }
      case 2: {
         DirectComparison();
         break;
      }
      case 3: {
         MajorityRule();
         break;
      }
   } 
}

/* Randomly trust in one sensed opinion */
void EPuck_Environment_Classification::VoterModel(){
        
	int size = receivedOpinions.size() - 1;
	if(size > -1){        
	   CRange<Real> sizeRange(0,size+0.9);
	   int index = (m_pcRNG->Uniform(sizeRange));
           opinion.actualOpinion = receivedOpinions[index].receivedOpinion;
	} 
}

/* Compare robot own opinion to a randomly sensed one, trust her only if it's stronger than robot's one */
void EPuck_Environment_Classification::DirectComparison(){
        
	int size = receivedOpinions.size() - 1;
	if(size > -1){  	
	   CRange<Real> sizeRange(0,size+0.9); // +0.9 is needed because else it never chose the last element
	   int index = (m_pcRNG->Uniform(sizeRange));
           if ( receivedOpinions[index].receivedQuality > opinion.quality ) 
	        opinion.actualOpinion = receivedOpinions[index].receivedOpinion;
	}
}

/* Trust to the more sensed opinion */
void EPuck_Environment_Classification::MajorityRule(){
        
	int numberOpinionsReceived[N_COL];
	
	/* Setting majority array to 0 */
        for ( int c = 0; c < N_COL; c++ )
		numberOpinionsReceived[c] = 0;

	/* For each received opinion, increment the correspondent cell. numberOpinionsReceived it's simply a contator for each color */
	for ( int i = 0; i<receivedOpinions.size(); i++ )
	       numberOpinionsReceived[receivedOpinions[i].receivedOpinion]++;
       
	opinion.actualOpinion = FindMaxOpinionReceived(numberOpinionsReceived, opinion.actualOpinion);
}


int EPuck_Environment_Classification::FindMaxOpinionReceived(int numberOpinionsReceived[], int actualOpinion){

	int max = 0, index = 0;
	
        for( int i = 0; i<N_COL; i++)
		if( numberOpinionsReceived[i] > max )
		{
			max = numberOpinionsReceived[i];
			index = i;
		}
	if(max == 0)
	   return actualOpinion;
	else
  	   return index;
}

/************************************************* MOVEMENT ****************************************************/
/***************************************************************************************************************/
/* Implement the moviment leaded by the random walk (see loop_function) */
void EPuck_Environment_Classification::Move(){ 
  if(movement.actualDirection == 0) // Go straight
    		 m_pcWheels->SetLinearVelocity(m_fWheelVelocity,  m_fWheelVelocity);
 	 else
  	   if(movement.actualDirection == 1) // Turn right
  		 m_pcWheels->SetLinearVelocity(m_fWheelVelocity,  -m_fWheelVelocity);
    	   else 
             if(movement.actualDirection == 2) // Turn left
	         m_pcWheels->SetLinearVelocity(-m_fWheelVelocity,  m_fWheelVelocity);
}

/************************************************* TURNING LEDS ON *********************************************/
/***************************************************************************************************************
0 = RED;
1 = GREEN; 
2 = BLUE                                                 
AGGIUNGERECOLORI 
*/
void EPuck_Environment_Classification::TurnLeds(){
     
     switch(opinion.actualOpinion) {

      case 0: {

	 opinion.actualOpCol = CColor::RED;
	 m_pcLEDs->SetAllColors(CColor::RED); 
         break;
      }
      case 1: {
         opinion.actualOpCol = CColor::GREEN;
	 m_pcLEDs->SetAllColors(CColor::GREEN);
         break;
      }
      case 2: {
	 opinion.actualOpCol = CColor::BLUE;
	 m_pcLEDs->SetAllColors(CColor::BLUE);
         break;
      }
   } 
}

/****************************************/
/****************************************/
 
REGISTER_CONTROLLER(EPuck_Environment_Classification, "epuck_environment_classification_controller")
