/* Include the controller definition */
#include "footbot_environment_classification.h"
/* Function definitions for XML parsing */
#include <argos3/core/utility/configuration/argos_configuration.h>
/* 2D vector definition */
#include <argos3/core/utility/math/vector2.h>
#include <argos3/plugins/robots/foot-bot/simulator/footbot_entity.h>
#include <argos3/core/simulator/simulator.h>
#include <stdio.h>
#include <stdlib.h>
#include <ctime>
#include <vector>   
#include <string>   
#include <iostream>
#include <fstream> 

#define ALPHA_CHANNEL		 30
#define COLOR_STRENGHT           255
#define MAX_LISTENING_TIME       40
#define N_COL			 3

/****************************************/
/****************************************/

CEnvironment::CEnvironment() :
   m_pcWheels (NULL), 
   m_fWheelVelocity (10.0f),
   m_pcRABA (NULL),
   m_pcRABS (NULL),
   m_cAlpha (10.0f),
   m_fDelta(0.5f),
   m_pcProximity(NULL),
   bigRange (0.0f,30000.0f),
   zeroOne (0.0f, 1.0f),
   m_cGoStraightAngleRange(-ToRadians(m_cAlpha),
                            ToRadians(m_cAlpha)) {}

CEnvironment::CollectedData::CollectedData() :
   count (1),
   lastCell (0) {}

CEnvironment::Opinion::Opinion() :
   countedCellOfActualOpinion (0)  {}


CEnvironment::Movement::Movement() :
   walkTime (3),
   actualDirection (0){}

/****************************************/
/****************************************/



/************************************************* INIT ********************************************************/
/***************************************************************************************************************/
void CEnvironment::SimulationState::Init(TConfigurationNode& t_node) {

   try{
	      /* Getting sigma, G value and the decision rule to follow */
	      GetNodeAttribute(t_node, "g", g);
	      GetNodeAttribute(t_node, "sigma", sigma);
	      GetNodeAttribute(t_node, "decision_rule", decision_rule);
        }
   catch(CARGoSException& ex) {
      THROW_ARGOSEXCEPTION_NESTED("Error initializing controller state parameters.", ex);
   }
}
 
void CEnvironment::Init(TConfigurationNode& t_node) {
   
   /* Initialize the actuators (and sensors) and the initial velocity as straight walking*/
   m_pcWheels    = GetActuator<CCI_DifferentialSteeringActuator>("differential_steering");
   m_pcProximity = GetSensor <CCI_FootBotProximitySensor >("footbot_proximity" );
   m_pcLEDs      = GetActuator<CCI_LEDsActuator                >("leds"                 );
   m_pcRABA      = GetActuator<CCI_RangeAndBearingActuator     >("range_and_bearing"    );
   m_pcRABS      = GetSensor  <CCI_RangeAndBearingSensor       >("range_and_bearing"    );
   m_pcRNG = CRandom::CreateRNG("argos");
   m_cGoStraightAngleRange.Set(-ToRadians(m_cAlpha), ToRadians(m_cAlpha));
   GetNodeAttributeOrDefault(t_node, "velocity", m_fWheelVelocity, m_fWheelVelocity);
   simulationParams.Init(GetNode(t_node, "simulation_parameters"));

   /* G and SIGMA have to been inserted in seconds in the configuration file. For this reason here are multiplied*10 (secods*10 = ticks) */
   simulationParams.sigma = simulationParams.sigma*10;
   simulationParams.g = simulationParams.g*10;
  
   /* Colours read from robots could be changed and added here! AGGIUNGERECOLORI */ 
   red.Set(COLOR_STRENGHT,0,0,ALPHA_CHANNEL);      // Change alphachannel has not effect visively, but changing COLOR_STRENGHT could make 
   green.Set(0,COLOR_STRENGHT,0,ALPHA_CHANNEL);    // cells more or less bright
   blue.Set(0,0,COLOR_STRENGHT,ALPHA_CHANNEL);

   /* Assign a random time for the exploration and diffusing states. "RemainingTime" are the ones decremented and checked to see if
      the state is finished. "DurationTime" are the ones used for catching statistics and save the times */
   m_sStateData.remainingExplorationTime = (m_pcRNG->Exponential(simulationParams.sigma));
   m_sStateData.explorDurationTime = m_sStateData.remainingExplorationTime;
   m_sStateData.remainingDiffusingTime = (m_pcRNG->Exponential((simulationParams.g)*(opinion.quality)))+30;
   m_sStateData.diffusingDurationTime = m_sStateData.remainingDiffusingTime;
   
   /* Statistic variables (not anymore used here but could be helpfull sometimes to catch statistics) */
   for(int c = 0; c<N_COL; c++)
   {
	m_sStateData.numberOfExplorations[c] = 1;
        m_sStateData.numberOfDiffusions[c] = 1;
        m_sStateData.exportTime[c] = 0;
        countedOfThisOpinion[c] = 0;
        totalCounted = 0;
   	opinion.exportQuality[c] = 0;
   }

   /* IC it's an helping variable to read others opinion */
   IC.receivedOpinion = 0;
   IC.receivedQuality = 0;
   IC.senderID = 0;
  
   /* Assign the initial state of the robots: all in exploration state*/
   m_sStateData.State = SStateData::STATE_EXPLORING;

   /* INITIAL QUALITY: has to be estimated in the first exploration state */
   opinion.quality = 0;    
}

/************************************************* CONTROL STEP ************************************************/
/***************************************************************************************************************/
void CEnvironment::ControlStep() {
  
  /* Turn leds according with actualOpinion */
  TurnLeds();
 
  /* Move robots following randomWalk */
  Move();

  /* Two different behaviours, depending on if they are diffusing or exploring */
  switch(m_sStateData.State) {
      
      case SStateData::STATE_EXPLORING: {
         Explore();
         break;
      }
      case SStateData::STATE_DIFFUSING: {
         Diffusing();
         break;
      }
   } 


/****OBSTACLE AVOIDANCE****/

/* Get readings from proximity sensor and sum them together */
const CCI_FootBotProximitySensor::TReadings& tProxReads = m_pcProximity->GetReadings();
CVector2 cAccumulator;
for(size_t i = 0; i < tProxReads.size(); ++i) {
    cAccumulator += CVector2(tProxReads[i].Value, tProxReads[i].Angle);
}

cAccumulator /= tProxReads.size();

/* If the angle of the vector is not small enough or the closest obstacle is not far enough curve a little */
CRadians cAngle = cAccumulator.Angle();
  if(!(m_cGoStraightAngleRange.WithinMinBoundIncludedMaxBoundIncluded(cAngle) && cAccumulator.Length() < m_fDelta )) {
     /* Turn, depending on the sign of the angle */
     if(cAngle.GetValue() > 0.0f) {
        m_pcWheels->SetLinearVelocity(m_fWheelVelocity, 0.0f);
     }
     else {
        m_pcWheels->SetLinearVelocity(0.0f, m_fWheelVelocity);
     }
  }
}


/************************************************* EXPLORING STATE *********************************************/
/***************************************************************************************************************/
void CEnvironment::Explore() {
  
	if(m_sStateData.remainingExplorationTime > 0){	// Still time for exploration state	
	 /* Nothing to do here. In prestep (loop_function), every exploring robots will update the counters */
	  m_sStateData.remainingExplorationTime--;
         }

	else{ // Change state and reset used variables 
    	   m_sStateData.remainingExplorationTime = (m_pcRNG->Exponential(simulationParams.sigma)); // Re-assign exponential time for the state
	   m_sStateData.explorDurationTime = m_sStateData.remainingExplorationTime;                // "Save" time for statistics
	   opinion.quality = (Real)((Real)(opinion.countedCellOfActualOpinion)/(Real)(collectedData.count));     // Calculate quality 
	   opinion.countedCellOfActualOpinion = 0; //    #Cells counted in the last exploration according with actualOpinion of the robot
	   collectedData.count = 1;                //    #Total cells counted in the last exploration state  
           m_sStateData.State = SStateData::STATE_DIFFUSING; 	// Change state
	 }
}

/************************************************* DIFFUSING STATE *********************************************/
/***************************************************************************************************************/
void CEnvironment::Diffusing() {
  
  /* If remainingDiffusingTime>0, it's still time to perform diffusing state */
  if (m_sStateData.remainingDiffusingTime > 0) 
  {	
    /* In the 3 lasts seconds (30 ticks) the robot starts listening other opinions while diffusing his opinion */ 
    if(  m_sStateData.remainingDiffusingTime < 30 ) 
       {
	 /* Every received data is stored in IC variable. Each IC variable will be inserted in receivedOpinions array. It will be used to 		    choose the next opinion, basing on decision rules. After a decision has been taken this array will be emptied. */
         const CCI_RangeAndBearingSensor::TReadings& tPackets = m_pcRABS->GetReadings();
	 for(size_t i = 0; i < tPackets.size() ; ++i) {

	       bool saved = false;   // saved = variable to not save opinions twice: if saved == true -> don't save the datas

	       /* IC = Helping variable for sensed opinions */
               IC.receivedOpinion = tPackets[i].Data[0]; // Store received opinion 
	       IC.senderID = tPackets[i].Data[3]; // Store id of the sender

	       /* Loop for sense quality value: quality has been sent using 3 cells of RAB datas */
 	       IC.receivedQuality=0;
               for ( int j = 1; j<3 ; ++j)
                     IC.receivedQuality = IC.receivedQuality*100 + tPackets[i].Data[j];
	       IC.receivedQuality = (Real) IC.receivedQuality / 10000;

	       /* Don't want to save already listened values */
               for(int j = 0; j < receivedOpinions.size(); ++j)
                   if(receivedOpinions[j].senderID == IC.senderID) 
                      saved = true;
	       
	       /* Don't want to save 0,0,0 values */
	       if(IC.senderID == 0)
		  saved = true;

	       /* Save value */
               if(!saved) 
                  receivedOpinions.push_back(IC);
	 }
       }

      /* Intermittence LEDS in diffusing state */
      if(m_sStateData.remainingDiffusingTime%2)
	 m_pcLEDs->SetAllColors(CColor::BLACK); 

      /* Following things will have always to be done if in diffusing state. Here robot sends its opinion, quality and ID */

      /* Send opinion */
      m_pcRABA->SetData(0,opinion.actualOpinion);
     
      /* Send quality */
      Real p = opinion.quality;   // helping variables
      UInt8 t;			  // helping variables
      for (int i = 0; i < 2; ++i)
	{
	   p = p*100;
	   t = (int)p;
           p = p - t;
	   m_pcRABA->SetData(i+1,t);
        }
      
      /* Send ID: an univoque transformation of the string id is calculated	
	 and sent to the other robots */
      std::string id = GetId();
      int idConversion = 0;
      for ( int i = 2; id[i] != '\0'; ++i )
      {
         idConversion += int(id[i]);
         idConversion = idConversion*10;
      }  
      m_pcRABA->SetData(3,idConversion);
 
      m_sStateData.remainingDiffusingTime--;	
  }
  else // Time to change to exploration state
    {
      /* Reset exponential random diffusing time */
      m_sStateData.remainingDiffusingTime = m_pcRNG->Exponential((simulationParams.g)*(opinion.quality))+30;    
      m_sStateData.diffusingDurationTime = m_sStateData.remainingDiffusingTime;

      /* Change to EXPLORING state and choose another opinion with decision rules */
      m_sStateData.State = SStateData::STATE_EXPLORING;
      DecisionRule(simulationParams.decision_rule);

      /* After decision has been taken, sensed values are deleted */
      receivedOpinions.clear();   
  }
}

/* DECISION RULE */
void CEnvironment::DecisionRule(int decision_rule)
{

     switch(decision_rule) {
      
      case 1: {
         VoterModel();
         break;
      }
      case 2: {
         DirectComparison();
         break;
      }
      case 3: {
         MajorityRule();
         break;
      }
   } 
}

/* Randomly trust in one sensed opinion */
void CEnvironment::VoterModel(){
        
	int size = receivedOpinions.size() - 1;
	if(size > -1){        
	   CRange<Real> sizeRange(0,size+0.9);
	   int index = (m_pcRNG->Uniform(sizeRange));
           opinion.actualOpinion = receivedOpinions[index].receivedOpinion;
	} 
}

/* Compare robot own opinion to a randomly sensed one, trust her only if it's stronger than robot's one */
void CEnvironment::DirectComparison(){
        
	int size = receivedOpinions.size() - 1;
	if(size > -1){  	
	   CRange<Real> sizeRange(0,size+0.9); // +0.9 is needed because else it never chose the last element
	   int index = (m_pcRNG->Uniform(sizeRange));
           if ( receivedOpinions[index].receivedQuality > opinion.quality ) 
	        opinion.actualOpinion = receivedOpinions[index].receivedOpinion;
	}
}

/* Trust to the more sensed opinion */
void CEnvironment::MajorityRule(){
        
	int numberOpinionsReceived[N_COL];
	
	/* Setting majority array to 0 */
        for ( int c = 0; c < N_COL; c++ )
		numberOpinionsReceived[c] = 0;

	/* For each received opinion, increment the correspondent cell. numberOpinionsReceived it's simply a contator for each color */
	for ( int i = 0; i<receivedOpinions.size(); i++ )
	       numberOpinionsReceived[receivedOpinions[i].receivedOpinion]++;
       
	opinion.actualOpinion = FindMaxOpinionReceived(numberOpinionsReceived, opinion.actualOpinion);
}


int CEnvironment::FindMaxOpinionReceived(int numberOpinionsReceived[], int actualOpinion){

	int max = 0, index = 0;
	
        for( int i = 0; i<N_COL; i++)
		if( numberOpinionsReceived[i] > max )
		{
			max = numberOpinionsReceived[i];
			index = i;
		}
	if(max == 0)
	   return actualOpinion;
	else
  	   return index;
}

/************************************************* MOVEMENT ****************************************************/
/***************************************************************************************************************/
/* Implement the moviment leaded by the random walk (see loop_function) */
void CEnvironment::Move(){ 
  if(movement.actualDirection == 0) // Go straight
    		 m_pcWheels->SetLinearVelocity(m_fWheelVelocity,  m_fWheelVelocity);
 	 else
  	   if(movement.actualDirection == 1) // Turn right
  		 m_pcWheels->SetLinearVelocity(m_fWheelVelocity,  -m_fWheelVelocity);
    	   else 
             if(movement.actualDirection == 2) // Turn left
	         m_pcWheels->SetLinearVelocity(-m_fWheelVelocity,  m_fWheelVelocity);
}

/************************************************* TURNING LEDS ON *********************************************/
/***************************************************************************************************************
0 = RED;
1 = GREEN; 
2 = BLUE                                                 
AGGIUNGERECOLORI 
*/
void CEnvironment::TurnLeds(){
     
     switch(opinion.actualOpinion) {
      
      case 0: {
	 opinion.actualOpCol = red;
	 m_pcLEDs->SetAllColors(CColor::RED); 
         break;
      }
      case 1: {
         opinion.actualOpCol = green;
	 m_pcLEDs->SetAllColors(CColor::GREEN);
         break;
      }
      case 2: {
	 opinion.actualOpCol = blue;
	 m_pcLEDs->SetAllColors(CColor::BLUE);
         break;
      }
   } 

}

/****************************************/
/****************************************/
 
REGISTER_CONTROLLER(CEnvironment, "footbot_environment_classification_controller")
